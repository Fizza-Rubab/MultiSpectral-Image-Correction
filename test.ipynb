{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "final_{image2_path}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "def parse_value(text, keyword):\n",
    "    pattern = re.escape(keyword) + r'\\s*=\\s*\"([^\"]*)\"'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_metadata(image_path):\n",
    "    with tifffile.TiffFile(image_path) as tif:\n",
    "        metadata = tif.pages[0].tags\n",
    "        tif_tags = {}\n",
    "        tif_tags['XMP'] = tif.pages[0].tags[700].value.decode('utf-8')\n",
    "\n",
    "    s = tif_tags['XMP']\n",
    "    # print(s)\n",
    "    dwarp_data = \"drone-dji:DewarpData\"\n",
    "    dwarp_data_para = parse_value(s, dwarp_data)\n",
    "    dwarp_coefficients  = [float(x) for x in dwarp_data_para[11:].split(',')]\n",
    "    calibrated_hmatrix = \"drone-dji:DewarpHMatrix\"\n",
    "    calibrated_hmatrix = [float(x) for x in parse_value(s, calibrated_hmatrix).split(',')]\n",
    "    print(len(calibrated_hmatrix), calibrated_hmatrix)\n",
    "    calibrated_hmatrix = np.array(calibrated_hmatrix).reshape((3,3))\n",
    "    print(calibrated_hmatrix)\n",
    "    centre_x_para = 'drone-dji:CalibratedOpticalCenterX'\n",
    "    centre_y_para = 'drone-dji:CalibratedOpticalCenterY'\n",
    "    vignettingData_para = 'drone-dji:VignettingData'\n",
    "    center_x = float(parse_value(s, centre_x_para))\n",
    "    center_y = float(parse_value(s, centre_y_para))\n",
    "    vignettingData_str = parse_value(s, vignettingData_para)\n",
    "    vignetting_data = [float(x) for x in vignettingData_str.split(',')]  # Convert string to list of floats\n",
    "    return center_x, center_y, vignetting_data, dwarp_coefficients, calibrated_hmatrix\n",
    "\n",
    "def undistort_image(image_path, outpath_img, coefficients):\n",
    "    center_x, center_y = coefficients[0], coefficients[1]\n",
    "    fx, fy, cx, cy, k1, k2, p1, p2, k3 = coefficients[2]\n",
    "    fx, fy, cx, cy, k1, k2, p1, p2, k3 = 2200.899902343750, 2200.219970703125, 10.609985351562, -6.575988769531, 0.008104680106, -0.042915198952, -0.000333522010, 0.000239991001, 0.000000000000\n",
    "    matrix = np.array([[fx, 0, center_x+cx], [0, fy, center_y+cy], [0, 0, 1]])\n",
    "    dist = np.array([k1, k2, p1, p2, k3])\n",
    "    # print(\"md\", matrix, dist)\n",
    "    with Image.open(image_path) as img:\n",
    "        w, h = img.size\n",
    "        # img_norm = cv2.normalize( np.array(img), None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        # print(img_norm.max(), img_norm.min())\n",
    "        newcameramtx, roi = cv2.getOptimalNewCameraMatrix(matrix, dist, (w,h), 1, (w,h))\n",
    "        dst = cv2.undistort(np.array(img), matrix, dist, newcameramtx)\n",
    "        print(np.array_equal(np.array(img), dst))\n",
    "        # print(dst.max(), dst.min())\n",
    "        undistorted_image = Image.fromarray(dst)\n",
    "        undistorted_image.save(outpath_img)\n",
    "\n",
    "def apply_vignetting_correction(image_path,outpath_img):\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        center_x, center_y, vignetting_data, dwarp_coefficients, calibrated_hmatrix = get_metadata(image_path)\n",
    "        print(center_x, center_y)\n",
    "        correction_img = np.zeros((height, width))\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                r = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)\n",
    "                correction_value = sum([k * (r ** i) for i, k in enumerate((vignetting_data))]) + 1.0\n",
    "                correction_img[y, x] = correction_value\n",
    "        img_norm = cv2.normalize( np.array(img), None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        corrected_img = img_norm * correction_img\n",
    "        corrected_img = np.clip(corrected_img, 0, 255).astype(np.uint8)\n",
    "        corrected_image = Image.fromarray(corrected_img)\n",
    "        corrected_image.save(outpath_img)\n",
    "    return (center_x, center_y, dwarp_coefficients, calibrated_hmatrix)\n",
    "\n",
    "def phase_alignment(image_path,outpath_img, parameters):\n",
    "    calibrated_hmatrix = parameters[-1]\n",
    "    calibrated_hmatrix = np.array([[9.891065e-01, 1.740813e-02, -1.592078e+01],\n",
    "                                   [-1.568817e-02, 9.885082e-01, 3.766531e+01],\n",
    "                                   [1.083204e-06, 5.127963e-07, 1.000000e+00]])\n",
    "    with Image.open(image_path) as img:\n",
    "        w, h = img.size\n",
    "        print(w, h)\n",
    "        transformed_image = cv2.warpPerspective(np.array(img), calibrated_hmatrix, (w, h))\n",
    "        print(np.array_equal(np.array(img), transformed_image))\n",
    "        transformed_image = Image.fromarray(transformed_image)\n",
    "        transformed_image.save(outpath_img)\n",
    "\n",
    "def ecc_alignment(image1_path, image2_path):\n",
    "    image1 = cv2.imread(image1_path, cv2.IMREAD_UNCHANGED)\n",
    "    image2 = cv2.imread(image2_path, cv2.IMREAD_UNCHANGED)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2, None)\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    matched_image = cv2.drawMatches(image1, keypoints1, image2, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    src_points = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_points = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    M, _ = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 5.0)\n",
    "    aligned_image2 = cv2.warpPerspective(image2, M, (image1.shape[1], image1.shape[0]))\n",
    "    print(np.array_equal(aligned_image2, image2))\n",
    "    print('final_{image2_path}')\n",
    "    cv2.imwrite('final_' + image2_path, aligned_image2)\n",
    "\n",
    "\n",
    "\n",
    "# image_path = r\"images\\DJI_20230928151039_0001_MS_R.TIF\"\n",
    "# outpath_img = r\"DJI_20230928151039_0001_MS_R.TIF\"\n",
    "# parameters = apply_vignetting_correction(image_path,outpath_img)\n",
    "# undistort_image(outpath_img, 'undistort_'+outpath_img, parameters)\n",
    "# phase_alignment('undistort_'+outpath_img, 'phase_undistort_'+outpath_img, parameters)\n",
    "ecc_alignment(r'NIR\\phase_undistort_DJI_20230928151039_0001_MS_NIR.TIF', r'R\\phase_undistort_DJI_20230928151039_0001_MS_R.TIF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('left12.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult.png',dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
